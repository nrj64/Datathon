{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e57e4ac-846d-45eb-a1fb-b5bf6f1f33f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16, 9)\n",
    "plt.style.use('fast')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Embedding, concatenate\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7aaa679-bbbb-41ae-a20c-976ed0d86b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo = pd.read_csv('df_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fb2f406-8ce2-4eb5-80c6-5e6de751d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos variables en el tipo correspondiente\n",
    "\n",
    "df_completo['ID_tienda'] = df_completo['ID_tienda'].astype(object)\n",
    "df_completo['Fecha_venta'] = pd.to_datetime(df_completo['Fecha_venta'])\n",
    "df_completo['ID_producto'] = df_completo['ID_producto'].astype(object)\n",
    "df_completo['Status'] = df_completo['Status'].astype(object)\n",
    "df_completo['ID_proveedor'] = df_completo['ID_proveedor'].astype(object)\n",
    "df_completo['Categoria'] = df_completo['Categoria'].astype(object)\n",
    "df_completo['Clasif_proveedor'] = df_completo['Clasif_proveedor'].astype(object)\n",
    "df_completo['Año'] = df_completo['Año'].astype(object)\n",
    "df_completo['Mes'] = df_completo['Mes'].astype(object)\n",
    "df_completo['Dia_del_Mes'] = df_completo['Dia_del_Mes'].astype(object)\n",
    "df_completo['Cluster'] = df_completo['Cluster'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0cdc69c-4050-4b35-9209-b3a6a4e968f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2352570329.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Filtrar datos para cada cluster\n",
    "cluster_0 = df_completo[df_completo['Cluster'] == 0]\n",
    "cluster_1 = df_completo[df_completo['Cluster'] == 1]\n",
    "cluster_2 = df_completo[df_completo['Cluster'] == 2]\n",
    "cluster_3 = df_completo[df_completo['Cluster'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82aa076b-eb41-4b69-be53-a602a413dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas 'Lag_1', 'Rolling_Mean_7' y 'Rolling_Std_7'\n",
    "df_completo = df_completo.drop(columns=['Lag_1', 'Rolling_Mean_7', 'Rolling_Std_7', 'Cluster', 'ID_tienda', 'Facturacion', 'Status', 'ID_proveedor', 'Categoria', 'Clasif_proveedor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1a999ce-f265-4578-86f4-bcbf7ee60f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar y preparar los datos\n",
    "df_completo['Fecha_venta'] = pd.to_datetime(df_completo['Fecha_venta'])\n",
    "df_completo.set_index('Fecha_venta', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1fb37bc-b700-4fcb-a157-be634b59325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_completo.to_csv('df_completo.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58f6d245-8997-4f66-b5be-9abd02d02bef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Categoria'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Separar características numéricas y categóricas\u001b[39;00m\n\u001b[1;32m      2\u001b[0m numeric_data \u001b[38;5;241m=\u001b[39m df_completo[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrecio_unidad\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m----> 3\u001b[0m categorical_data \u001b[38;5;241m=\u001b[39m \u001b[43mdf_completo\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mID_producto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategoria\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPromocion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDia_sem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDia_del_Mes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Categoria'] not in index\""
     ]
    }
   ],
   "source": [
    "# Separar características numéricas y categóricas\n",
    "numeric_data = df_completo[['Precio_unidad']]\n",
    "categorical_data = df_completo[['ID_producto', 'Categoria', 'Promocion', 'Dia_sem', 'Mes', 'Dia_del_Mes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8e48d-e72c-4552-8b2f-eb097c147ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871bf664-9fab-4bd9-80c2-534f7a0a8eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar características numéricas\n",
    "scaler = MinMaxScaler()\n",
    "numeric_data = scaler.fit_transform(numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27773a02-7c54-4b70-86fb-fee5ab85a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar características categóricas\n",
    "encoder = OneHotEncoder()  # Asegúrate de tener la última versión de sklearn o elimina el parámetro sparse\n",
    "categorical_data_encoded = encoder.fit_transform(categorical_data)\n",
    "#numeric_data = encoder.fit_transform(numeric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c87c8-b33c-486c-8ad0-591c37a3e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numeric_data.shape)\n",
    "print(categorical_data_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74d8b5-c366-40e3-93cc-1b537ddfe6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9c81b1-97bd-4ddd-9db3-6313d33cda34",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356d50d-812c-4534-8047-40bef70f04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_data_encoded = categorical_data_encoded.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da6c8b-45d0-4496-81a0-3153de8fc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación basada en tus dimensiones\n",
    "#numeric_data = np.random.rand(113254, 1)  # Datos numéricos aleatorios\n",
    "#categorical_data_encoded = np.random.rand(113254, 982)  # Datos categóricos codificados aleatorios\n",
    "\n",
    "# Concatenar datos numéricos y categóricos\n",
    "data = np.hstack((numeric_data, categorical_data_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85dc8c5-ed1e-4912-874a-ff3d996cbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar dispositivos disponibles, GPU debería aparecer si está configurado correctamente\n",
    "print(\"Dispositivos disponibles:\", tf.config.list_physical_devices())\n",
    "\n",
    "# Configurar TensorFlow para que use la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configuración para evitar el uso de toda la memoria de la GPU de una sola vez\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb2df3e-be69-4068-affd-12daf686e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "# Parámetros para la preparación de datos\n",
    "n_future = 15  # Número de días que deseamos prever en el futuro\n",
    "n_past = 1096  # Número de días pasados que usaremos para predecir el futuro\n",
    "\n",
    "# Asegúrate de que 'data' sea un array de CuPy\n",
    "data2 = cp.asarray(data)\n",
    "\n",
    "# Preparar datos para LSTM usando CuPy\n",
    "X, y = [], []\n",
    "for i in range(n_past, len(data) - n_future + 1):\n",
    "    X.append(data2[i - n_past:i])\n",
    "    y.append(data2[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "# Convertir listas a arrays de CuPy\n",
    "X = cp.array(X)\n",
    "y = cp.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb2c593-a41c-4641-acbf-0c178b047699",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Preparar datos para LSTM\n",
    "n_future = 15  # Número de días que deseamos prever en el futuro\n",
    "n_past = 1096   # Número de días pasados que usaremos para predecir el futuro\n",
    "X, y = [], []\n",
    "for i in range(n_past, len(data) - n_future + 1):\n",
    "    X.append(data[i - n_past:i])\n",
    "    y.append(data[i + n_future - 1:i + n_future, 0])  # Asumiendo que el objetivo es la primera columna\n",
    "\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0613a9e-22fb-42fe-b791-758978ab159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c931db2-59be-4afc-bdca-5230f3fe36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el modelo LSTM\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model_input = Input(shape=input_shape)\n",
    "x = LSTM(50, return_sequences=True)(model_input)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(50)(x)\n",
    "x = Dense(1)(x)  # Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fb9770-0d7e-4dd8-86fa-e920cb9222dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model_input, outputs=x)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009417c0-b298-4c16-ad7a-19c973f79cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93fe818-7419-4862-a02f-9f6cafbc6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3abe86-d3b5-44eb-8446-1b9fd4257115",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd1ca5f-4ee4-4b4d-a7ee-d7a5e1494310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6a949-956b-47f6-9006-28dab79fe247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulación de datos para el ejemplo\n",
    "# 'y_test' serían tus valores reales y 'predictions' las predicciones del modelo\n",
    "y_test = np.random.rand(100)  # 100 valores reales simulados\n",
    "predictions = y_test + np.random.normal(0, 0.1, 100)  # Predicciones con ruido añadido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661a98d-18ec-4501-aa7c-46c80e3448f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear gráfico para comparar predicciones con la realidad\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_test, label='Realidad', color='blue')\n",
    "plt.plot(predictions, label='Predicciones', color='red', linestyle='--')\n",
    "plt.title('Comparación de Predicciones vs Realidad')\n",
    "plt.xlabel('Tiempo / Índice')\n",
    "plt.ylabel('Valor de la Serie Temporal')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a96f40-8b89-4e2c-b84c-bad186affed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool, cpu_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbf524-c2e5-4153-bbba-a2b73b160957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir para un producto usando el modelo de red neuronal\n",
    "def predecir_producto_neural(args):\n",
    "    producto, fecha_inicio = args\n",
    "    dias_a_predecir = 15\n",
    "    fechas_prediccion = pd.date_range(start=fecha_inicio, periods=dias_a_predecir, freq='D')\n",
    "    df_prediccion = pd.DataFrame(fechas_prediccion, columns=['Fecha_venta'])\n",
    "    # resto del código...\n",
    "\n",
    "    df_prediccion['ID_producto'] = producto\n",
    "    df_prediccion['Precio_unidad'] = df_prediccion['Fecha_venta'].apply(lambda x: obtener_precio(x, producto))\n",
    "\n",
    "    # Agregar más transformaciones o adaptaciones según las necesidades del modelo neural\n",
    "    # Aquí es donde necesitas asegurarte de que los datos están en el formato correcto para el modelo\n",
    "    # Por ejemplo, si tu modelo toma entradas normalizadas o tiene requerimientos específicos de forma\n",
    "\n",
    "    # Preparar datos para la red neuronal\n",
    "    # Esto incluiría normalización, y tal vez reshaping si es necesario para el modelo\n",
    "    input_data = preparar_datos_para_red_neural(df_prediccion)\n",
    "\n",
    "    # Realizar predicciones con el modelo de red neuronal\n",
    "    predicciones = neural_network_model.predict(input_data)\n",
    "\n",
    "    # Post-procesar las predicciones si es necesario (por ejemplo, redondeo, ajuste de escala)\n",
    "    df_prediccion['Predicciones'] = predicciones.flatten()  # Asegúrate de ajustar esta línea según sea necesario\n",
    "\n",
    "    return df_prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66f58ec-f569-4269-9f1f-fc8e78141485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos numéricos\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def normalizar_columnas(df, columnas):\n",
    "    df[columnas] = scaler.fit_transform(df[columnas])\n",
    "    return df\n",
    "\n",
    "# Suponiendo que df_merged es tu DataFrame completo con datos de todos los productos\n",
    "df_completo = normalizar_columnas(df_completo, ['Cant_vendidas', 'Precio_unidad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8782b9-5ee1-4219-947b-95f7c8838bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para predecir para un producto usando el modelo de red neuronal\n",
    "def predecir_producto_neural(args):\n",
    "    producto, fecha_inicio = args\n",
    "    dias_a_predecir = 15\n",
    "    fechas_prediccion = pd.date_range(start=fecha_inicio, periods=dias_a_predecir, freq='D')\n",
    "    df_prediccion = pd.DataFrame(fechas_prediccion, columns=['Fecha_venta'])\n",
    "    # resto del código...\n",
    "\n",
    "    df_prediccion['ID_producto'] = producto\n",
    "    df_prediccion['Precio_unidad'] = df_prediccion['Fecha_venta'].apply(lambda x: obtener_precio(x, producto))\n",
    "\n",
    "    # Agregar más transformaciones o adaptaciones según las necesidades del modelo neural\n",
    "    # Aquí es donde necesitas asegurarte de que los datos están en el formato correcto para el modelo\n",
    "    # Por ejemplo, si tu modelo toma entradas normalizadas o tiene requerimientos específicos de forma\n",
    "\n",
    "    # Preparar datos para la red neuronal\n",
    "    # Esto incluiría normalización, y tal vez reshaping si es necesario para el modelo\n",
    "    input_data = preparar_datos_para_red_neural(df_prediccion)\n",
    "\n",
    "    # Realizar predicciones con el modelo de red neuronal\n",
    "    predicciones = neural_network_model.predict(input_data)\n",
    "\n",
    "    # Post-procesar las predicciones si es necesario (por ejemplo, redondeo, ajuste de escala)\n",
    "    df_prediccion['Predicciones'] = predicciones.flatten()  # Asegúrate de ajustar esta línea según sea necesario\n",
    "\n",
    "    return df_prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3feec3-8ac9-47fb-bfde-a8140525f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_precio(fecha, producto):\n",
    "    # Supongamos que df_merged_last_prices es un DataFrame que tiene precios históricos de productos\n",
    "    # Intenta obtener el precio en la fecha dada. Si no es posible, devuelve el precio medio conocido.\n",
    "    precio = df_merged_last_prices[(df_merged_last_prices['ID_producto'] == producto) &\n",
    "                                   (df_merged_last_prices['Fecha_venta'] <= fecha)].nlargest(1, 'Fecha_venta')['Precio_unidad']\n",
    "    if precio.empty:\n",
    "        return df_merged_last_prices[df_merged_last_prices['ID_producto'] == producto]['Precio_unidad'].mean()\n",
    "    else:\n",
    "        return precio.iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84f2260-c858-45ca-9b0c-6011731e4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_completo['Precio_unidad'] = df_completo['Fecha_venta'].apply(lambda x: obtener_precio(x, producto))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8fe396-8aed-4a1b-bfb9-6dde29c035f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegúrate de que 'cluster_0' está definido correctamente y contiene la columna 'ID_producto'\n",
    "productos = df_completo['ID_producto'].unique()\n",
    "# Ejecución en paralelo para todos los productos (si es necesario)\n",
    "if __name__ == \"__main__\":\n",
    "    # Convertimos la fecha de inicio a un objeto datetime\n",
    "    fecha_inicio = datetime.strptime('2024-07-01', \"%Y-%m-%d\")  # Asegúrate de obtener esta fecha correctamente\n",
    "    args = [(producto, fecha_inicio) for producto in productos]\n",
    "\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        all_predictions = pool.map(predecir_producto_neural, args)\n",
    "\n",
    "    # Combinar todas las predicciones en un solo DataFrame\n",
    "    all_predictions_df = pd.concat(all_predictions, ignore_index=True)\n",
    "\n",
    "    # Procesar y guardar los resultados como lo hiciste anteriormente\n",
    "    all_predictions_df.to_csv('predicciones_neural_network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5df2db-9cec-4a41-bf5b-fd4bb4427c77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a3ce8-af3d-46ee-a28e-85e6a65dfa06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
